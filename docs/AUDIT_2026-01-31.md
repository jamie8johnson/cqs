# Design Audit - 2026-01-31

Audit of `DESIGN.md` (version 0.6.1-draft)

## Summary

Found **14 issues**: 3 critical, 5 moderate, 6 minor.

---

## Critical Issues

### C1. ort execution provider import paths incorrect

**Location:** Design doc lines ~520-540, ~555-575

**Problem:** Design shows `CUDAExecutionProvider` and `TensorRTExecutionProvider` but ort 2.x uses different module paths.

**Design doc:**
```rust
use ort::execution_providers::{
    CUDAExecutionProvider, TensorRTExecutionProvider, ExecutionProvider as EP,
};
```

**Actual ort 2.x API:**
```rust
use ort::execution_providers as ep;
// Then use: ep::CUDA::default(), ep::TensorRT::default()
```

**Fix:** Update imports and usage:
```rust
use ort::execution_providers as ep;

fn select_provider() -> ExecutionProvider {
    if ep::CUDA::default().is_available().unwrap_or(false) {
        return ExecutionProvider::CUDA { device_id: 0 };
    }
    // ...
}

// Session creation:
builder.with_execution_providers([
    ep::CUDA::default().with_device_id(device_id).build()
])?
```

---

### C2. Model file size incorrect

**Location:** Design doc line ~86

**Problem:** Design says model is ~523MB, actual is **547MB**.

**Impact:** Download progress bars, disk space checks will be wrong.

**Fix:** Update to 547MB (or use `model_fp16.onnx` at 274MB for faster loads).

---

### C3. Missing `token_type_ids` handling

**Location:** Design doc embedding code (~630-655)

**Problem:** Design only passes `input_ids` and `attention_mask`. Some ONNX exports of nomic-embed-text-v1.5 may expect `token_type_ids`.

**Actual:** The official ONNX export does NOT require `token_type_ids` (confirmed). But this should be documented/verified at runtime.

**Recommendation:** Add a note that token_type_ids is not needed, and consider adding defensive code that checks the model's expected inputs at session creation.

---

## Moderate Issues

### M1. Tree-sitter grammar version mismatch risk

**Location:** Design doc Cargo.toml (~1028-1034)

**Problem:** Design specifies tree-sitter 0.26 with grammar crates at 0.23.x. These versions have different dev dependencies:
- Grammar crates 0.23.x have dev-dep on tree-sitter ^0.23
- tree-sitter 0.26 is newer

**Actual compatibility:** Works due to `tree-sitter-language` abstraction layer, but untested.

**Recommendation:** Add integration test that parses sample code in all 5 languages. Document that compatibility relies on abstraction layer.

---

### M2. hf-hub `model()` takes owned String

**Location:** Design doc line ~588

**Problem:** Code shows `api.model(MODEL_REPO.to_string())` which is correct, but the constant is defined as `&str`. This requires allocation on every call.

**Current:**
```rust
const MODEL_REPO: &str = "nomic-ai/nomic-embed-text-v1.5";
let repo = api.model(MODEL_REPO.to_string());
```

**Better:** Document this is intentional, or use a static String in a lazy_static/once_cell.

---

### M3. SQLite connection setup incomplete

**Location:** Design doc schema (~715-745) vs Store implementation

**Problem:** Design shows WAL pragma in schema comments but no Rust code to execute them.

**Missing:**
```rust
impl Store {
    fn open(path: &Path) -> Result<Self> {
        let conn = Connection::open(path)?;
        conn.pragma_update(None, "journal_mode", "WAL")?;
        conn.pragma_update(None, "busy_timeout", 5000)?;
        // ...
    }
}
```

---

### M4. Search function signature doesn't match implementation

**Location:** Design doc lines ~788-810

**Problem:** `search()` signature shows it takes `threshold: f32` but implementation filters by threshold inside. The `query_map` closure structure is also incorrect - can't access `row` and `score` together as shown.

**Design doc (incorrect):**
```rust
.query_map([], |row| {
    let embedding_bytes: Vec<u8> = row.get(10)?;
    let score = cosine_similarity(...);
    Ok((row, score))  // Can't return row from closure
})?
```

**Fix:** Need two-phase: fetch all, then filter/sort in Rust.

---

### M5. Missing L2 normalization verification

**Location:** Design doc line ~694

**Problem:** `cosine_similarity` has a debug_assert checking normalization, but this won't catch issues in release builds.

**Recommendation:** Either:
1. Always normalize (defensive), or
2. Add a runtime check with proper error handling, or
3. Document that embeddings MUST be pre-normalized

---

## Minor Issues

### m1. TypeScript query captures anonymous arrow functions twice

**Location:** Design doc lines ~217-229

**Problem:** The query has both specific patterns for arrow functions AND a catch-all `(arrow_function) @function`. This will capture the same arrow function twice (once as assigned variable, once as standalone).

**Fix:** Add `#not-match?` predicate or filter duplicates by byte range in code.

---

### m2. Python docstring extraction accesses wrong node

**Location:** Design doc lines ~448-461

**Problem:** For Python, docstrings are inside the function body, not preceding siblings. The code tries `node.child_by_field_name("body")` which is correct, but `named_child(0)` may not be the docstring if there's a decorator.

**Better:** Use tree-sitter query to find docstrings directly.

---

### m3. Go chunk type detection is redundant

**Location:** Design doc lines ~370-376

**Problem:** `infer_chunk_type` checks `node.kind() == "method_declaration"` for Go, but the query already captures this distinctly. The check is redundant but harmless.

---

### m4. Missing error on empty query results

**Location:** CLI query handling

**Problem:** Design shows query output but not what happens when no results found. Should show "No results found" message.

---

### m5. Chunk ID format may conflict

**Location:** Design doc line ~349

**Problem:** Chunk ID is `{path}:{line_start}`. If two functions start on same line (rare but possible with macros/minified code), IDs will collide.

**Recommendation:** Use `{path}:{line_start}:{content_hash[:8]}` or similar.

---

### m6. Missing batch size configuration in Embedder

**Location:** Design doc Embedder struct (~492-515)

**Problem:** Design mentions batch sizes (16 GPU, 4 CPU) in text but struct doesn't store them. Need to add `batch_size: usize` field.

---

## Verified Correct

- ✓ tree-sitter `StreamingIterator` usage
- ✓ `QueryMatch.captures` field access
- ✓ `query.capture_index_for_name()` pattern
- ✓ `Session::builder()?.commit_from_file()` pattern
- ✓ `try_extract_array()` returns `ArrayViewD`
- ✓ `ort::inputs!` macro syntax
- ✓ tokenizers `encode_batch(Vec<String>, true)` works
- ✓ `Encoding::get_ids()` returns `&[u32]`
- ✓ hf-hub `repo.get(&str)` pattern
- ✓ rusqlite `Vec<u8>` for BLOB storage
- ✓ nomic model outputs `sentence_embedding` (pre-pooled)
- ✓ Input dtype is INT32
- ✓ Output is 768 dimensions
- ✓ Task prefixes (`search_document:`, `search_query:`) required

---

## Recommendations

1. **Before implementing:** Fix C1 (ort imports) in design doc
2. **During implementation:** Add integration tests for tree-sitter compatibility (M1)
3. **Consider:** Using `model_fp16.onnx` (274MB) instead of full precision (547MB) - 2x smaller, minimal quality loss
4. **Add to design:** Runtime model input validation
5. **Add to design:** Explicit "no results" CLI output

---

## Files to Update

1. `DESIGN.md` - Fix issues C1, C2, M3, M4, m1, m5, m6
2. `docs/HUNCHES.md` - Note tree-sitter version risk
